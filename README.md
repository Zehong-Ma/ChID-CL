# 基于对比学习的中文成语完型填空

## 实验目的

本项目采用ChID中文成语完型填空数据集，要求模型能够从一系列成语候选中选择最正确的成语填入语篇的特定位置。

```
{
    "groundTruth": ["一目了然", "先入为主"], 
    "candidates": [["明明白白", "添油加醋", "一目了然", "残兵败将", "杂乱无章", "心中有数", "打抱不平"], ["矫揉造作", "死不瞑目", "先入为主", "以偏概全", "期期艾艾", "似是而非", "追根究底"]], 
    "content": "【分析】父母对孩子的期望这一点可以从第一段中找到“即使是学校也只是我们送孩子去接受实用教育的地方，而不是让他们为了知识而去追求知识的地方。”至此，答案选项[C]#idiom#。而选项[B]显然错误。选项[A]这个干扰项是出题人故意拿出一个本身没有问题，但是不适合本处的说法来干扰考生。考生一定要警惕#idiom#的思维模式，在做阅读理解的时候，不能按照自己的直觉和知识瞎猜，一定要以原文为根据。选项[D]显然也是不符合家长的期望的。", 
    "realCount": 2
}
```

如上所示，在`content`中有两处`#idiom#`标志。以第一个标志处为例，模型要从候选成语`["明明白白", "添油加醋", "一目了然", "残兵败将", "杂乱无章", "心中有数", "打抱不平"]`选择最合适的成语`一目了然`填入此处。

### 数据集下载

本文数据集ChID由 **[ChID: A Large-scale Chinese IDiom Dataset for Cloze Test](https://www.aclweb.org/anthology/P19-1075)** 提出。训练集包含句子50w条，验证集和测试集各有2w条句子。

[下载链接（北大网盘）](https://disk.pku.edu.cn:443/link/3510A73BA4793A830B0179DF795330C8)

考虑到同学们的训练资源各不相同，我们鼓励大家在1w，5w，10w三种训练集规格中**选择一种**进行实验；相应的训练集均已提前切分好，放在网盘以供大家下载。

## 动机（Motivitation）

### 基准模型

![image-20221211143734674](README/image-20221211143734674.png)

### 基准模型存在的问题

1. **成语应当当作一个整体去理解**而不是一个字一个字，一个字一个字去理解预测可能带来**两个问题**：

* 每个成语的字旁边跟什么字，搜索空间太大，不易搜索到合适的字，汉语的字有21128个，四个字全部预测正确的随机概率为$(\frac{1}{21128})^4$，概率很小，即使考虑到不同字旁边出现的字的概率是不一样的，这极可能是一个极小的概率。
* 成语中，一字之差可能导致意思截然不同，这样的成语并不稀少，例如成语：
    * 不孚众望，不负众望，不以为然，不以为意。

2. **一个成语可能有多个意思**，单凭一个一个字去理解成语可能存在问题，例如成语。
    * 灯红酒绿。

3. **不能光凭字的表面去理解成语**，单凭一个一个字去理解成语可能存在问题：

* 存在很多字和意思并不匹配的成语，例如很多成语来自用典，其字和意思存在很大的差距：
    * 塞翁失马
    * 高山流水
    * 曲高和寡

### 解决办法

1. 针对问题一：尝试着把成语当成一个token去理解，而不是四个token。
2. 针对问题二和问题三：尝试着加入成语的解释。

## 模型介绍

模型基于预训练模型中常用的掩码语言模型（Masked Language Modeling）实现，采用中文roberta作为backbone。

我们尝试了两个模型。

### 对比方法（Contrastive Method）

![image-20221211145610461](README/image-20221211145610461.png)

* 给成语整体加一个Mask，也就是直接预测成语整体。

* 成语（图中的例子为：画蛇添足）经过RoBERTa编码得到Word Embed，经过FC层微调的到词向量$C_i^p$。

* 尽量拉近成语和[Mask]预测出的向量的距离，拉远和其它成语之间的距离，即设置两个Loss函数：

    <figure class="half">
        <img src="README/image-20221211150050428.png" width="500" />
        <img src="README/image-20221211150234765.png" width="500" />
    </figure>

* 两个Loss函数相加。

    ![image-20221211150302016](README/image-20221211150302016.png)

### 加入成语解释的对比方法（Contrastive Method with Extra Knowledge）

![](README/image-20221211150431013.png)

* 给成语整体加一个Mask，也就是直接预测成语整体。

* 成语（图中的例子为：画蛇添足）经过RoBERTa编码得到Word Embed，经过FC层微调的到词向量$C_i^p$。

* 尽量拉近成语和[Mask]预测出的向量的距离，同时拉近成语的意思和[Mask]预测出的向量的距离，即设置两个Loss函数：

    <figure class="half">
        <img src="README/image-20221211150912617.png" width="500" />
        <img src="README/image-20221211150924292.png" width="500" />
    </figure>

* 两个Loss函数相加。

    ![image-20221211150950872](README/image-20221211150950872.png)



### 代码实现

具体实现代码参见`contrastive_model.py`。

## 实验结果

| Model | Dev   | Test  | Train scale |
| ----- | ----- | ----- | ----------- |
| CoM   | 57.09 | 57.02 | 1w          |
| CoM   | 72.06 | 72.08 | 5w          |
| CoM   | 75.84 | 76.02 | 10w         |
| CoM   | 83.12 | 83.10 | all         |

| Model | Dev   | Test  | Train scale |
| ----- | ----- | ----- | ----------- |
| CoMEK | 63.98 | 64.1  | 1w          |
| CoMEK | 73.72 | 73.59 | 5w          |
| CoMEK | 76.81 | 76.74 | 10w         |
| CoMEK | 82.93 | 83.14 | all         |

我们的模型相较于human的水平仍有待提升。

| Model       |  dev  | test  |
| ----------- | :---: | :---: |
| Ours (CoM)  | 83.12 | 83.10 |
| Ours(CoMEK) | 82.93 | 83.14 |
| Human       |   -   | 87.1  |

## 未来工作

* 用更大的batch size进行对比学习。
* 不同Loss的消融实验。

# Reference: 

+  [CHID_baseline](https://github.com/Zce1112zslx/ChID_baseline)